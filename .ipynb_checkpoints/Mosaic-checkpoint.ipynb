{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==3.4.2.16 in /home/fatma/anaconda3/envs/grad/lib/python3.6/site-packages (3.4.2.16)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/fatma/anaconda3/envs/grad/lib/python3.6/site-packages (from opencv-python==3.4.2.16) (1.15.4)\n",
      "Requirement already satisfied: opencv-contrib-python==3.4.2.16 in /home/fatma/anaconda3/envs/grad/lib/python3.6/site-packages (3.4.2.16)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/fatma/anaconda3/envs/grad/lib/python3.6/site-packages (from opencv-contrib-python==3.4.2.16) (1.15.4)\n"
     ]
    }
   ],
   "source": [
    "#import pacakges \n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "import numpy\n",
    "from pylab import *\n",
    "from numpy import *\n",
    "from numpy import array\n",
    "import random;\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "!pip install opencv-python==3.4.2.16\n",
    "!pip install opencv-contrib-python==3.4.2.16\n",
    "#!pip install opencv-python\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ransac function to get the best homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac(corr, thresh):\n",
    "    maxInliers = []\n",
    "    finalH = None\n",
    "    randomFour = np.zeros((4,4)) \n",
    "    for i in range(1000):\n",
    "        #find 4 random points to calculate a homography\n",
    "        point1 = corr[random.randrange(0, len(corr))]\n",
    "        randomFour [0]=point1\n",
    "        point2 = corr[random.randrange(0, len(corr))]\n",
    "        randomFour [1]=point2\n",
    "        point3 = corr[random.randrange(0, len(corr))]\n",
    "        randomFour [2]=point3\n",
    "        point4 = corr[random.randrange(0, len(corr))]\n",
    "        randomFour [3]=point4\n",
    "\n",
    "        #call the homography function on those points\n",
    "        h = findHomography(randomFour)\n",
    "        if h is  None:\n",
    "            continue\n",
    "        else:\n",
    "            inliers = []\n",
    "\n",
    "        #for every point in the corres\n",
    "            for i in range(len(corr)):\n",
    "                d = geometricDistance(corr[i], h)\n",
    "                if d < 5:\n",
    "                    inliers.append(corr[i])\n",
    "\n",
    "            if len(inliers) > len(maxInliers):\n",
    "                maxInliers = inliers\n",
    "                finalH = h\n",
    "           \n",
    "\n",
    "            if len(maxInliers) > (len(corr)*0.4):\n",
    "                break\n",
    "    return finalH, maxInliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_array(corr):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    xdash=[]\n",
    "    ydash=[]\n",
    "    b=[]\n",
    "    for i in range(4):\n",
    "        x.append(corr[i][0])\n",
    "        y.append(corr[i][1])\n",
    "        xdash.append(corr[i][2])\n",
    "        ydash.append(corr[i][3])\n",
    "        b.append(corr[i][2])\n",
    "        b.append(corr[i][3])\n",
    "    return x,y,xdash,ydash,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometricDistance(correspondence, h):\n",
    "\n",
    "    p1 = np.array([correspondence[0], correspondence[1], 1])\n",
    "    estimatep2 = np.dot(h, p1)\n",
    "    estimatep2 = correct(estimatep2)\n",
    "\n",
    "    p2 = np.array([correspondence[2], correspondence[3], 1])\n",
    "    error = p2 - estimatep2\n",
    "    return np.linalg.norm(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(A):\n",
    "    if A[2]!=1:\n",
    "        A[0] = (A[0]/A[2])\n",
    "        A[1] = (A[1]/A[2])\n",
    "        A[2] = (A[2]/A[2])\n",
    "    return A\n",
    "def round_arr(A):\n",
    "    A[0]= round(A[0])\n",
    "    A[1]= round(A[1])\n",
    "    A[2]= round(A[2])\n",
    "    return A  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findHomography (corr):\n",
    "    x,y,xdash,ydash,b = split_array(corr)\n",
    "    \n",
    "    M = np.array([\n",
    "          [x[0],y[0],1,0,0,0,-x[0]*xdash[0], -y[0]*xdash[0]],\n",
    "          [0,0,0,x[0],y[0],1,-x[0]*ydash[0], -y[0]*ydash[0]],\n",
    "          [x[1],y[1],1,0,0,0,-x[1]*xdash[1],-y[1]*xdash[1]],\n",
    "          [0,0,0,x[1],y[1],1,-x[1]*ydash[1],-y[1]*ydash[1]],\n",
    "          [x[2],y[2],1,0,0,0,-x[2]*xdash[2],-y[2]*xdash[2]],\n",
    "          [0,0,0,x[2],y[2],1,-x[2]*ydash[2],-y[2]*ydash[2]],\n",
    "          [x[3],y[3],1,0,0,0,-x[3]*xdash[3],-y[3]*xdash[3]],\n",
    "          [0,0,0,x[3],y[3],1,-x[3]*ydash[3],-y[3]*ydash[3]]\n",
    "      ])\n",
    "   # print(\"M = \" ,M)\n",
    "    try:\n",
    "        a = np.dot(np.linalg.inv(M),b)\n",
    "        a = np.append(a,1)\n",
    "        return a.reshape(3,3)\n",
    "    except:\n",
    "        a = None\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ginput to find correspondances function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoints(image):\n",
    "    img1 = Image.open(image) \n",
    "    plt.figure(1)\n",
    "    plt.imshow(img1)\n",
    "    print(\"Please click\") \n",
    "    x = plt.ginput(4)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warping the source image to the destination image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions needed for warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_max_min_Axis (A,B,C,D):\n",
    "    \n",
    "    min_x = min(A[0],B[0],C[0],D[0])\n",
    "    max_x = max(A[0],B[0],C[0],D[0])\n",
    "    min_y = min(A[1],B[1],C[1],D[1])\n",
    "    max_y = max(A[1],B[1],C[1],D[1])\n",
    "   \n",
    "    return min_x , max_x , min_y , max_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### take into consideration that for homogrpahy calculations [x,y,1] is actually placed as [y,x] in the 2D matrix.\n",
    "def Get_new_boundaries (h,N,M):\n",
    "    A= [0,0,1]\n",
    "    A_new  = np.dot(h,A)\n",
    "    A_new = correct(A_new)\n",
    "    A_new = round_arr(A_new)\n",
    "    A_new[1] = get_coor(A_new,img1.shape[0])\n",
    "    print(\"old value of A = \",A,\"new value = \",A_new)\n",
    "    B=[0,N-1,1]\n",
    "    B_new = np.matmul(h,B )\n",
    "    B_new = correct(B_new)\n",
    "    B_new = round_arr(B_new)\n",
    "    B_new[1] = get_coor(B_new,img1.shape[0])\n",
    "    C=[M-1,0,1]\n",
    "    print(\"old value of B = \",B,\"new value = \",B_new)\n",
    "    C_new = np.matmul(h,C )\n",
    "    C_new = correct(C_new)\n",
    "    C_new = round_arr(C_new)\n",
    "    C_new[1] = get_coor(C_new,img1.shape[0])\n",
    "    D=[M-1,N-1,1]\n",
    "    print(\"old value of C= \",C,\"new value = \",C_new)\n",
    "    D_new = np.matmul(h,D )\n",
    "    D_new = correct(D_new)\n",
    "    D_new = round_arr(D_new)\n",
    "    D_new[1] = get_coor(D_new,img1.shape[0])\n",
    "    print(\"old value of D = \",D,\"new value = \",D_new)\n",
    "    return A_new,B_new,C_new,D_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we limit the size of the output image height to the original images height.\n",
    "def get_coor(point,M):\n",
    "    if point[1]<0:\n",
    "        point[1]=0\n",
    "    if point[1]>M:\n",
    "        point[1]=M-1\n",
    "    return point[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(src_img,dimensions,h_inv):\n",
    "    #prepare x and y arrays for interpolation\n",
    "    #image 2 because inverse warping is made so that we get image 2 pixel values.\n",
    "    x = np.arange(0, src_img.shape[1], 1)\n",
    "    y = np.arange(0, src_img.shape[0], 1)\n",
    "    \n",
    "    blue = src_img[:, :, 0] \n",
    "    green =  src_img[:, :, 1] \n",
    "    red= src_img[:, :, 2] \n",
    "    \n",
    "    min_x= dimensions['min_x']\n",
    "    min_y= dimensions['min_y']\n",
    "    new_w= dimensions['new_w']\n",
    "    new_h= dimensions['new_h']\n",
    "    \n",
    "    \n",
    "    new_img_red= np.zeros((src_img.shape[0],new_h+src_img.shape[1]))\n",
    "    new_img_blue=np.zeros((src_img.shape[0],new_h+src_img.shape[1]))\n",
    "    new_img_green=np.zeros((src_img.shape[0],new_h+src_img.shape[1]))\n",
    "\n",
    "    interp_spline_green = RectBivariateSpline(y.reshape(-1,1), x.reshape(-1,1), green)\n",
    "    interp_spline_red = RectBivariateSpline(y.reshape(-1,1), x.reshape(-1,1), red)\n",
    "    interp_spline_blue= RectBivariateSpline(y.reshape(-1,1), x.reshape(-1,1), blue)\n",
    "\n",
    "    ##start warping loop\n",
    "    for i in range (int(min_x),int(min_x+new_w),1):\n",
    "        for j in range (int(min_y),int((min_y+new_h)),1):\n",
    "            point = [i,j,1]\n",
    "            co_ord = np.matmul(h_inv,point)\n",
    "            co_ord = correct(co_ord)\n",
    "            xi=co_ord[0]\n",
    "            yi=co_ord[1]\n",
    "            if (xi>=0 and yi>=0):\n",
    "                if(i < new_h+src_img.shape[1]):\n",
    "\n",
    "                    intensity=int(interp_spline_red.ev(yi, xi))\n",
    "                    new_img_red[j][i] = intensity\n",
    "\n",
    "\n",
    "                    intensity=int(interp_spline_blue.ev(yi, xi))\n",
    "                    new_img_blue[j][i] = intensity\n",
    "\n",
    "                    intensity=int(interp_spline_green.ev(yi, xi))\n",
    "                    new_img_green[j][i] = intensity\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                new_img_red[j][i] = 0\n",
    "                new_img_green[j][i] = 0\n",
    "                new_img_blue[j][i] = 0\n",
    "                \n",
    "    return new_img_red,new_img_green,new_img_blue\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_bgr_warped_image(warped_blue,warped_red,warped_green,dimensions,src):\n",
    "    rows = dimensions['rows']\n",
    "    cols = dimensions['cols']\n",
    "    new_h =dimensions['new_h']\n",
    "    new_img = np.zeros((src.shape[0],src.shape[1]+new_h,3), 'uint8')\n",
    "    new_img[:,:,0]=warped_blue\n",
    "    new_img[:,:,1]=warped_green\n",
    "    new_img[:,:,2]=warped_red\n",
    "    return new_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_warping(h,src):\n",
    "    \n",
    "    ## check the bounding box position and size of the warped image using forward warping.\n",
    "    print(\"Fed to homography and resulted from homography:\")\n",
    "    print('------------------------------------------------')\n",
    "    A,B,C,D = Get_new_boundaries(h,src.shape[0],src.shape[1])\n",
    "\n",
    "    # the solution is in the following format\n",
    "    ## col, row\n",
    "    ## x,y\n",
    "    \n",
    "    min_x , max_x , min_y, max_y = Get_max_min_Axis (A,B,C,D)\n",
    "    print(\"min_y =\", min_y , \"max_y = \", max_y ,\"min_x = \", min_x,\"max_x=\", max_x)\n",
    "    \n",
    "    new_h = int(round(abs(max_y - min_y)))\n",
    "    new_w = int(round(abs(max_x- min_x)))\n",
    "    print(\"The new width is (# no of columns) =\",new_w)\n",
    "    print(\"The new height is (# no of rows) =\",new_h)\n",
    "    \n",
    "    #start by giving the the warping fns each of the following:\n",
    "     ## min_x and min_y => to determine starting point of the warpd image in the dst image.\n",
    "     ##new_h and new_w => to determine the size of the warped image in the dst image.\n",
    "        \n",
    "    dimensions = {}\n",
    "    dimensions['min_x']= min_x\n",
    "    dimensions['min_y'] = min_y\n",
    "    dimensions['new_w']= new_w\n",
    "    dimensions['new_h']=new_h\n",
    "\n",
    "    #compute inverse homography\n",
    "    h_inv = np.linalg.inv(h)\n",
    "\n",
    "    warped_red,warped_green,warped_blue = warp_image(src,dimensions,h_inv)\n",
    "    \n",
    "    #initialize the new image that will sticth the two images and the merge the bgr warped channels.\n",
    "\n",
    "    dimensions['rows'] = src.shape[0]\n",
    "    dimensions['cols'] = src.shape[1]+new_h\n",
    "\n",
    "    new_img = form_bgr_warped_image(warped_blue,warped_red,warped_green,dimensions,src)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stitch the two images together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_images(new_img,dst):\n",
    "    new_img[0:dst.shape[0],0:dst.shape[1]]= dst\n",
    "    return new_img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *******Load the two images to be stitched*******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images 1 and 2\n",
    "img1 = array(Image.open('./Images/image1.jpg')) #dest\n",
    "img2 = array(Image.open('./Images/image2.jpg'))\n",
    "\n",
    "gray= cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)\n",
    "gray2= cv2.cvtColor(img2,cv2.COLOR_BGR2RGB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) get Homography from Ginput Corresponding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get matching points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please click\n",
      "[(883.2555565020248, 321.7963030914595), (924.4287123068657, 329.8519205315371), (748.1001972296119, 494.54454375090097), (908.3174774267106, 496.3346809598071)]\n",
      "Please click\n",
      "[(440.19659729775776, 302.99986239794515), (477.78947868478645, 309.26534262911656), (295.19548337636127, 460.5319367816845), (450.0423519467414, 468.5875542217621)]\n"
     ]
    }
   ],
   "source": [
    "## start by getting points from ginput()\n",
    "pts_src = getPoints('./Images/image1.jpg')\n",
    "print(pts_src)\n",
    "pts_dst=getPoints('./Images/image2.jpg')\n",
    "print(pts_dst)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated homography [[ 2.27730266e+00  1.15345304e+00  6.01470291e+01]\n",
      " [ 2.25000336e-01  2.24384343e+00 -2.64457084e+02]\n",
      " [ 5.91037823e-04  1.11741391e-03  1.00000000e+00]]\n",
      "actual homogrpahy [[ 2.27729299e+00  1.15344274e+00  6.01499750e+01]\n",
      " [ 2.24998767e-01  2.24383255e+00 -2.64454696e+02]\n",
      " [ 5.91034072e-04  1.11740277e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "corrs = np.concatenate((pts_dst,pts_src),axis=1)\n",
    " \n",
    "h=findHomography(corrs)\n",
    "print(\"calculated homography\", h)\n",
    "\n",
    "# make sure our homography matches with that of openCv\n",
    "h, status = cv2.findHomography(np.array(pts_dst),np.array(pts_src))\n",
    "print(\"actual homogrpahy\", h)\n",
    "\n",
    "#They match dudeee, duh!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Get homography using sift only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    Use Sift to get matching point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found keypoints in image 2: 4476\n",
      "Found keypoints in image 1: 5739\n"
     ]
    }
   ],
   "source": [
    "# Initiate SIFT detector\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp1, src = sift.detectAndCompute(gray2,None)\n",
    "kp2, dst = sift.detectAndCompute(gray,None)\n",
    "print (\"Found keypoints in image 2: \" + str(len(kp1)))\n",
    "print (\"Found keypoints in image 1: \" + str(len(kp2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## match the points using Brute-Force matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a mathcer to match the point the sift correspondances\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.match(src, dst)\n",
    "keypoints = [kp1,kp2]\n",
    "correspondenceList = []\n",
    "\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(src,dst, k=2)\n",
    "# Sort them in the order of their distance.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "# Distance between descriptors. The lower, the better it is.\n",
    "# choose desctriptors of small distances \n",
    "    if m.distance < 0.7*n.distance:\n",
    "        (x1, y1) = keypoints[0][m.queryIdx].pt\n",
    "        (x2, y2) = keypoints[1][m.trainIdx].pt\n",
    "        good.append([x1, y1, x2, y2])\n",
    "\n",
    "corrs= np.array((good))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose four random points to get the homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[348.12036133 363.07241821 795.81555176 394.10333252]\n",
      " [389.040802   401.72384644 839.99224854 431.52215576]\n",
      " [182.60444641 543.35998535 642.21313477 579.21136475]\n",
      " [436.29727173 507.06118774 895.58117676 537.77624512]]\n"
     ]
    }
   ],
   "source": [
    "randomFour = np.zeros((4,4)) \n",
    "    #find 4 random points to calculate a homography\n",
    "point1 = corrs[random.randrange(0, len(corrs))]\n",
    "randomFour [0]=point1\n",
    "point2 = corrs[random.randrange(0, len(corrs))]\n",
    "randomFour [1]=point2\n",
    "point3 = corrs[random.randrange(0, len(corrs))]\n",
    "randomFour [2]=point3\n",
    "point4 = corrs[random.randrange(0, len(corrs))]\n",
    "randomFour [3]=point4\n",
    "print(randomFour)\n",
    "#call the homography function on those points\n",
    "h = findHomography(randomFour)\n",
    "#print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Get homography by SIFT AND RANSAC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found keypoints in image 2: 4476\n",
      "Found keypoints in image 1: 5739\n"
     ]
    }
   ],
   "source": [
    "# Initiate SIFT detector\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp1, src = sift.detectAndCompute(gray2,None)\n",
    "kp2, dst = sift.detectAndCompute(gray,None)\n",
    "print (\"Found keypoints in image 2: \" + str(len(kp1)))\n",
    "print (\"Found keypoints in image 1: \" + str(len(kp2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## match the points using Brute-Force matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4476\n"
     ]
    }
   ],
   "source": [
    "#use a mathcer to match the point the sift correspondances\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.match(src, dst)\n",
    "keypoints = [kp1,kp2]\n",
    "correspondenceList = []\n",
    "\n",
    "for match in matches:\n",
    "            (x1, y1) = keypoints[0][match.queryIdx].pt\n",
    "            (x2, y2) = keypoints[1][match.trainIdx].pt\n",
    "            correspondenceList.append([x1, y1, x2, y2])\n",
    "\n",
    "corrs = np.array((correspondenceList))\n",
    "estimation_thresh = 0.4\n",
    "print(len(corrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ransac to get the optimal Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found a singular matrix but ignored it\n",
      "Final homography:  [[ 7.41248724e-01  4.83710141e-02  4.41589992e+02]\n",
      " [-1.44972099e-01  9.02715342e-01  7.94209823e+01]\n",
      " [-2.33366661e-04 -3.53398873e-05  1.00000000e+00]]\n",
      "Final inliers count:  1183\n",
      "not optimal \n"
     ]
    }
   ],
   "source": [
    "#Run the ransac\n",
    "h, inliers = ransac(corrs, estimation_thresh)\n",
    "\n",
    "print (\"Final homography: \", h)\n",
    "print (\"Final inliers count: \", len(inliers))\n",
    "h = np.array(h)\n",
    "\n",
    "if len(inliers) < (0.4*len(corrs)):\n",
    "    print(\"not optimal \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fed to homography and resulted from homography:\n",
      "------------------------------------------------\n",
      "old value of A =  [0, 0, 1] new value =  [446.  77.   1.]\n",
      "old value of B =  [0, 682, 1] new value =  [487. 682.   1.]\n",
      "old value of C=  [1023, 0, 1] new value =  [1.609e+03 0.000e+00 1.000e+00]\n",
      "old value of D =  [1023, 682, 1] new value =  [1.675e+03 6.820e+02 1.000e+00]\n",
      "min_y = 0.0 max_y =  682.0 min_x =  446.0 max_x= 1675.0\n",
      "The new width is (# no of columns) = 1229\n",
      "The new height is (# no of rows) = 682\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_img = perform_warping(h,img2)\n",
    "\n",
    "#plot the warped image\n",
    "figure(2)\n",
    "plt.imshow(new_img)\n",
    "plt.show(block=False)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stitch the two images together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img= stitch_images(new_img,img1)\n",
    "figure (3)\n",
    "#plot the final stitched image.\n",
    "plt.imshow(new_img)\n",
    "plt.show(block =False)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test using open cv functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.warpPerspective(img2,np.array(h),(img1.shape[1] + img2.shape[1], img1.shape[0]))\n",
    "\n",
    "##plot the warped imageby open cv fn\n",
    "figure(2)\n",
    "plt.imshow(dst)\n",
    "plt.show(block=False)\n",
    "#plt.close()\n",
    "\n",
    "#plot the final stitched image by openCv\n",
    "dst[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "plt.imshow(dst,cmap='gray')\n",
    "plt.show(block= False)\n",
    "#plt.close()\n",
    "\n",
    "#Viola! they match :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
